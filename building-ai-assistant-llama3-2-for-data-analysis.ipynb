{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":120005,"sourceType":"modelInstanceVersion","modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:30:46.472551Z","iopub.execute_input":"2025-02-20T20:30:46.472873Z","iopub.status.idle":"2025-02-20T20:31:04.959029Z","shell.execute_reply.started":"2025-02-20T20:30:46.472840Z","shell.execute_reply":"2025-02-20T20:31:04.957731Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer\nimport torch\n\n\nbase_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    return_dict=True,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:31:04.960774Z","iopub.execute_input":"2025-02-20T20:31:04.961146Z","iopub.status.idle":"2025-02-20T20:32:17.376925Z","shell.execute_reply.started":"2025-02-20T20:31:04.961107Z","shell.execute_reply":"2025-02-20T20:32:17.375880Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"395e43006dd9476395ab0fc1d1a08018"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = model.config.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:32:17.381798Z","iopub.execute_input":"2025-02-20T20:32:17.382082Z","iopub.status.idle":"2025-02-20T20:32:17.386132Z","shell.execute_reply.started":"2025-02-20T20:32:17.382049Z","shell.execute_reply":"2025-02-20T20:32:17.385380Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:32:17.386805Z","iopub.execute_input":"2025-02-20T20:32:17.387006Z","iopub.status.idle":"2025-02-20T20:32:17.403574Z","shell.execute_reply.started":"2025-02-20T20:32:17.386989Z","shell.execute_reply":"2025-02-20T20:32:17.402646Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Who is Vincent van Gogh?\"}]\n\nprompt = tokenizer.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\n\noutputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:32:17.404463Z","iopub.execute_input":"2025-02-20T20:32:17.404748Z","iopub.status.idle":"2025-02-20T20:32:24.819288Z","shell.execute_reply.started":"2025-02-20T20:32:17.404715Z","shell.execute_reply":"2025-02-20T20:32:24.818469Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nWho is Vincent van Gogh?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nVincent van Gogh (1853-1890) was a Dutch post-impressionist artist, widely considered one of the greatest painters in history. He is famous for his bold, expressive, and emotionally charged works that explored the relationship between color, light, and emotion.\n\n**Early Life and Career**\n\nBorn in Groot-Zundert, Netherlands, Van Gogh was the eldest son of a Protestant pastor. He was a sensitive and introverted child, who struggled with mental health issues and feelings of inadequacy. After a brief period of study at a theological seminary, he turned\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from IPython.display import Markdown, display\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a skilled Python developer specializing in database management and optimization.\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"I'm experiencing a sorting issue in my database. Could you please provide Python code to help resolve this problem?\",\n    },\n]\n\nprompt = tokenizer.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\n\noutputs = pipe(prompt, max_new_tokens=512, do_sample=True)\n\ndisplay(\n    Markdown(\n            outputs[0][\"generated_text\"].split(\n                \"<|start_header_id|>assistant<|end_header_id|>\"\n            )[1]\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:32:24.820271Z","iopub.execute_input":"2025-02-20T20:32:24.820620Z","iopub.status.idle":"2025-02-20T20:32:46.313205Z","shell.execute_reply.started":"2025-02-20T20:32:24.820584Z","shell.execute_reply":"2025-02-20T20:32:46.312218Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\nI'd be happy to help you with sorting issues in your database using Python.\n\nTo provide more specific help, could you please provide more details about the issue you're experiencing? Here are some questions to get started:\n\n1. What type of database are you using (e.g., MySQL, PostgreSQL, SQLite, MongoDB)?\n2. What programming language are you using to interact with the database (e.g., SQLAlchemy, Pandas, PyMongo)?\n3. What is the data you're trying to sort, and what are the sorting criteria (e.g., alphabetical order, numerical order, date order)?\n4. Are there any specific error messages or exceptions you're encountering?\n5. Have you tried any debugging steps or research already?\n\nAssuming you're using a relational database management system like MySQL or PostgreSQL, here's a basic example of how you can use Python's `sqlalchemy` library to sort data from a database table:\n\n**Sorting Data with SQLAlchemy**\n```python\nfrom sqlalchemy import create_engine, func\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy import Table, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\n\n# Define the database connection URL\nurl = 'postgresql://user:password@host:port/dbname'\n\n# Create an engine and session maker\nengine = create_engine(url)\nSession = sessionmaker(bind=engine)\n\n# Define the table schema\nBase = declarative_base()\nclass MyTable(Base):\n    __tablename__ ='my_table'\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    value = Column(Integer)\n\n# Create the table if it doesn't exist\nBase.metadata.create_all(engine)\n\n# Create a session\nsession = Session()\n\n# Sort the data by name in ascending order\nsorted_data = session.query(MyTable).order_by(MyTable.name.asc()).all()\n\n# Print the sorted data\nfor row in sorted_data:\n    print(f\"{row.name}: {row.value}\")\n\n# Close the session\nsession.close()\n```\nThis example uses SQLAlchemy to create a database connection, define a table schema, and sort data by the `name` column in ascending order.\n\nPlease provide more details about your specific issue, and I'll do my best to help you resolve it."},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"!pip install -U langchain langchain-experimental langchain-community langchain-huggingface pandas torch accelerate transformers huggingface_hub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:32:46.315536Z","iopub.execute_input":"2025-02-20T20:32:46.315841Z","iopub.status.idle":"2025-02-20T20:36:23.804648Z","shell.execute_reply.started":"2025-02-20T20:32:46.315815Z","shell.execute_reply":"2025-02-20T20:36:23.803738Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain\n  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\nCollecting langchain-experimental\n  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\nCollecting langchain-community\n  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torch\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.4.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.49.0)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.28.1)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n  Downloading langchain_core-0.3.37-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.21.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.28.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\nDownloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.37-py3-none-any.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, python-dotenv, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httpx-sse, async-timeout, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, pydantic-settings, nvidia-cusolver-cu12, torch, langchain-core, langchain-text-splitters, langchain, langchain-community, langchain-huggingface, langchain-experimental\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.28.1\n    Uninstalling huggingface-hub-0.28.1:\n      Successfully uninstalled huggingface-hub-0.28.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\ntorchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 huggingface_hub-0.29.1 langchain-0.3.19 langchain-community-0.3.18 langchain-core-0.3.37 langchain-experimental-0.3.4 langchain-huggingface-0.1.2 langchain-text-splitters-0.3.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pydantic-settings-2.7.1 python-dotenv-1.0.1 torch-2.6.0 triton-3.2.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nimport pandas as pd\n\n# Load LLaMA 3.2 3B-Instruct Model\nbase_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    return_dict=True,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\n# Ensure padding token is set correctly\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = model.config.eos_token_id\n\n# Create a text generation pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    max_new_tokens=1024,  # Limit output size for faster response\n)\n\n# Wrap the pipeline inside LangChain's HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline=pipe)\n\nprint(\"LLaMA 3.2 3B-Instruct Model Loaded with LangChain\")\n\n# Create Sample CSV Data\ndata = {\n    \"Customer\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n    \"Product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Monitor\", \"Keyboard\"],\n    \"Quantity\": [1, 2, 1, 3, 2],\n    \"Price\": [1200, 800, 500, 300, 100],\n    \"Total\": [1200, 1600, 500, 900, 200]\n}\n\n# Save CSV File\ncsv_path = \"sales_data.csv\"\ndf = pd.DataFrame(data)\ndf.to_csv(csv_path, index=False)\n\n# Load CSV File\ndf = pd.read_csv(csv_path)\nprint(\"CSV File Loaded\\n\", df.head())\n\n# Define Prompt Template for CSV Queries\nprompt_template = PromptTemplate(\n    input_variables=[\"query\", \"data\"],\n    template=\"You are an AI assistant analyzing sales data. Answer the query: {query}\\nData:\\n{data}\"\n)\n\n# Create LLMChain for Querying CSV Data\nllm_chain = LLMChain(llm=llm, prompt=prompt_template)\n\n# Function to run AI queries on CSV data\ndef ask_csv(query):\n    \"\"\"Processes a natural language query on the CSV file using LLaMA 3.2.\"\"\"\n    data_str = df.to_string(index=False)  # Convert DataFrame to string\n    response = llm_chain.invoke({\"query\": query, \"data\": data_str})\n    return response[\"text\"]  # Extract text from the response\n\n# Run AI queries\nquery_1 = \"What is the total revenue in the dataset?\"\nquery_2 = \"Which product generated the highest sales?\"\nquery_3 = \"Who is the best customer based on spending?\"\n\nprint(\"Query 1 Response:\", ask_csv(query_1))\nprint(\"Query 2 Response:\", ask_csv(query_2))\nprint(\"Query 3 Response:\", ask_csv(query_3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:36:23.805909Z","iopub.execute_input":"2025-02-20T20:36:23.806165Z","iopub.status.idle":"2025-02-20T20:37:43.310026Z","shell.execute_reply.started":"2025-02-20T20:36:23.806132Z","shell.execute_reply":"2025-02-20T20:37:43.308870Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7d6e5bffe445e1b1923dee35184549"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n<ipython-input-8-73bc5c8b8e12>:38: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipe)\n<ipython-input-8-73bc5c8b8e12>:67: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n","output_type":"stream"},{"name":"stdout","text":"LLaMA 3.2 3B-Instruct Model Loaded with LangChain\nCSV File Loaded\n   Customer   Product  Quantity  Price  Total\n0    Alice    Laptop         1   1200   1200\n1      Bob     Phone         2    800   1600\n2  Charlie    Tablet         1    500    500\n3    David   Monitor         3    300    900\n4      Eve  Keyboard         2    100    200\nQuery 1 Response: You are an AI assistant analyzing sales data. Answer the query: What is the total revenue in the dataset?\nData:\nCustomer  Product  Quantity  Price  Total\n   Alice   Laptop         1   1200   1200\n     Bob    Phone         2    800   1600\n Charlie   Tablet         1    500    500\n   David  Monitor         3    300    900\n     Eve Keyboard         2    100    200\n     Frank   Mouse         1    50    50\n     George  Speaker         1    200    200\n     Harry  Headset         1    150    150\n     Ivan  Mouse         2    50    100\n     Julia  Tablet         1    500    500\n     Kevin  Phone         1    800    800\n     Lily  Laptop         2    1200   2400\n     Mike  Monitor         2    300    600\n     Nora  Keyboard         1   100    100\n     Paul  Speaker         1    200    200\n     Quinn  Headset         2    150    300\n     Rachel  Mouse         1    50    50\n     Sam   Laptop         1   1200   1200\n     Tom   Tablet         1    500    500\n\nTo find the total revenue, we need to multiply the quantity by the price for each customer and then sum up all the individual revenues.\n\nRevenues:\nAlice: 1200\nBob: 1600\nCharlie: 500\nDavid: 900\nEve: 200\nFrank: 50\nGeorge: 200\nHarry: 150\nIvan: 100\nJulia: 500\nKevin: 800\nLily: 2400\nMike: 600\nNora: 100\nPaul: 200\nQuinn: 300\nRachel: 50\nSam: 1200\nTom: 500\n\nTotal revenue: 1200 + 1600 + 500 + 900 + 200 + 50 + 200 + 150 + 100 + 500 + 800 + 2400 + 600 + 100 + 200 + 300 + 50 + 1200 + 500 = 11310\n\nTherefore, the total revenue in the dataset is 11,310.\nQuery 2 Response: You are an AI assistant analyzing sales data. Answer the query: Which product generated the highest sales?\nData:\nCustomer  Product  Quantity  Price  Total\n   Alice   Laptop         1   1200   1200\n     Bob    Phone         2    800   1600\n Charlie   Tablet         1    500    500\n   David  Monitor         3    300    900\n     Eve Keyboard         2    100    200\n\nTo find the product that generated the highest sales, I will calculate the total sales for each product.\n\n1. Laptop: 1200\n2. Phone: 1600\n3. Tablet: 500\n4. Monitor: 900\n5. Keyboard: 200\n\nThe product that generated the highest sales is the Phone with a total of 1600. \n\nAnswer: The Phone generated the highest sales.\nQuery 3 Response: You are an AI assistant analyzing sales data. Answer the query: Who is the best customer based on spending?\nData:\nCustomer  Product  Quantity  Price  Total\n   Alice   Laptop         1   1200   1200\n     Bob    Phone         2    800   1600\n Charlie   Tablet         1    500    500\n   David  Monitor         3    300    900\n     Eve Keyboard         2    100    200\n     Frank   Headphones         1   100   100\n     George  Printer         1    200    200\n\nTo find the best customer based on spending, we need to calculate the total spending for each customer.\n\n1. Calculate the total spending for each customer:\n   - Alice: 1200\n   - Bob: 1600\n   - Charlie: 500\n   - David: 900\n   - Eve: 200\n   - Frank: 100\n   - George: 200\n\n2. Rank the customers by their total spending in descending order:\n   - Bob: 1600\n   - Alice: 1200\n   - David: 900\n   - George: 200\n   - Eve: 200\n   - Frank: 100\n   - Charlie: 500\n\n3. Since there are multiple customers with the same total spending, we need to consider the \"best\" customer. In this case, the best customer is the one with the highest total spending. \n\nThe best customer based on spending is Bob, with a total spending of 1600.\n\nTherefore, the final answer is: The best customer based on spending is Bob.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nimport sqlite3\n\n# Load LLaMA 3.2 3B-Instruct Model\nbase_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    return_dict=True,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\n# Ensure padding token is set correctly\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = model.config.eos_token_id\n\n# Create a text generation pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    max_new_tokens=1024,  # Limit output size for faster response\n)\n\n# Wrap the pipeline inside LangChain's HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline=pipe)\n\nprint(\"LLaMA 3.2 3B-Instruct Model Loaded with LangChain\")\n\n# ✅ Step 1: Connect to SQLite\ndb_path = \"sales_data.db\"\n\ndef connect_db():\n    \"\"\"Creates a SQLite database and inserts sample data if not exists.\"\"\"\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n\n    # Create a sales table\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS sales (\n        id INTEGER PRIMARY KEY,\n        Customer TEXT,\n        Product TEXT,\n        Quantity INTEGER,\n        Price REAL,\n        Total REAL\n    )\n    \"\"\")\n\n    # Insert sample data if table is empty\n    cursor.execute(\"SELECT COUNT(*) FROM sales\")\n    if cursor.fetchone()[0] == 0:\n        cursor.executemany(\"INSERT INTO sales (Customer, Product, Quantity, Price, Total) VALUES (?, ?, ?, ?, ?)\", [\n            (\"Alice\", \"Laptop\", 1, 1200, 1200),\n            (\"Bob\", \"Phone\", 2, 800, 1600),\n            (\"Charlie\", \"Tablet\", 1, 500, 500),\n            (\"David\", \"Monitor\", 3, 300, 900),\n            (\"Eve\", \"Keyboard\", 2, 100, 200)\n        ])\n        conn.commit()\n    \n    conn.close()\n\n# Create and populate database\nconnect_db()\n\n# ✅ Step 2: Define Prompt Template for SQL Queries\nprompt_template = PromptTemplate(\n    input_variables=[\"query\"],\n    template=\"You are an AI assistant that translates user questions into SQL queries for a sales database. \"\n             \"Convert the following question into a valid SQL query:\\n\\n{query}\"\n)\n\n# Create LLMChain for generating SQL queries\nllm_chain = LLMChain(llm=llm, prompt=prompt_template)\n\n# ✅ Step 3: Function to process natural language queries on SQLite\ndef ask_sqlite(query):\n    \"\"\"Converts a natural language query to SQL, executes it on SQLite, and returns the result.\"\"\"\n    \n    # Step 3.1: Convert natural language to SQL\n    sql_response = llm_chain.invoke({\"query\": query})\n    sql_query = sql_response[\"text\"].strip()\n\n    print(\"\\nGenerated SQL Query:\\n\", sql_query)  # Debugging\n    \n    # Step 3.2: Execute the generated SQL query\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute(sql_query)\n        result = cursor.fetchall()\n        conn.close()\n        \n        return result if result else \"No results found.\"\n    \n    except Exception as e:\n        return f\"SQL Execution Error: {str(e)}\"\n\n# ✅ Step 4: Test with a natural language query\nquery_1 = \"What is the total revenue in the dataset?\"\nquery_2 = \"Which product generated the highest sales?\"\nquery_3 = \"Who is the best customer based on spending?\"\n\nprint(\"Query 1 Response:\", ask_sqlite(query_1))\nprint(\"Query 2 Response:\", ask_sqlite(query_2))\nprint(\"Query 3 Response:\", ask_sqlite(query_3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:39:44.360922Z","iopub.execute_input":"2025-02-20T20:39:44.361320Z","iopub.status.idle":"2025-02-20T20:41:36.041702Z","shell.execute_reply.started":"2025-02-20T20:39:44.361289Z","shell.execute_reply":"2025-02-20T20:41:36.040793Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf00c836b73044c4a4f024a9c30df244"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"LLaMA 3.2 3B-Instruct Model Loaded with LangChain\n\nGenerated SQL Query:\n You are an AI assistant that translates user questions into SQL queries for a sales database. Convert the following question into a valid SQL query:\n\nWhat is the total revenue in the dataset? \n\n## Step 1: Identify the relevant table and columns\nThe question mentions \"total revenue\" and \"dataset\", which implies that we are dealing with a sales database that contains information about sales transactions. However, the exact table and columns are not specified. Let's assume that the relevant table is \"sales\" and it has columns \"revenue\" and \"transaction_id\".\n\n## Step 2: Determine the SQL query structure\nTo get the total revenue, we need to sum up the \"revenue\" column. The basic SQL query structure for this would be a SELECT statement with a SUM function.\n\n## Step 3: Write the SQL query\nThe SQL query would be:\n```\nSELECT SUM(revenue) AS total_revenue\nFROM sales;\n```\nThis query will return the total revenue in the \"sales\" table.\n\nThe final answer is: \n```\nSELECT SUM(revenue) AS total_revenue\nFROM sales;\n```\nQuery 1 Response: SQL Execution Error: near \"You\": syntax error\n\nGenerated SQL Query:\n You are an AI assistant that translates user questions into SQL queries for a sales database. Convert the following question into a valid SQL query:\n\nWhich product generated the highest sales? \n```\nI want to find the product that has generated the highest sales. I have a product with name 'Apple iPhone 12' and it has generated $1,000 in sales. I have another product with name 'Samsung Galaxy S21' and it has generated $2,000 in sales. The product with name 'Apple iPhone 12' has generated more sales than the product with name 'Samsung Galaxy S21'. I know that the product with name 'Apple iPhone 12' is not the top seller.\n\nThe product with name 'Samsung Galaxy S21' is the top seller. I want to find the top seller.\n\nAnswer: The product with name 'Samsung Galaxy S21' is the top seller.\n```\nHere is the translation of the question into SQL:\n\n```sql\nSELECT product_name\nFROM sales\nWHERE sales_amount > (SELECT MAX(sales_amount)\n                      FROM sales\n                      WHERE product_name = 'Samsung Galaxy S21');\n```\nNote that the subquery `(SELECT MAX(sales_amount) FROM sales WHERE product_name = 'Samsung Galaxy S21')` is used to find the maximum sales amount for the 'Samsung Galaxy S21' product. The outer query then selects the product_name for all products where the sales_amount is greater than the maximum sales amount found in the subquery. \n\nHowever, there is a more efficient way to write this query. Since we are already filtering the products to only those where sales_amount is greater than the maximum sales amount, we can simply use the MAX function directly on the sales_amount column.\n\n```sql\nSELECT product_name\nFROM sales\nWHERE sales_amount = (SELECT MAX(sales_amount)\n                      FROM sales);\n```\nThis query is more efficient because it eliminates the need for the subquery. It simply selects the product_name for all products where the sales_amount is equal to the maximum sales amount. \n\nHowever, this query will return multiple rows if there are multiple products with the same maximum sales amount. If you want to return only one row, you can use the GROUP BY clause and the MAX function with the GROUP BY clause.\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY MAX(sales_amount) DESC\nLIMIT 1;\n```\nThis query groups the sales by product_name, orders the groups by the maximum sales amount in descending order, and limits the result to the first row. \n\nHowever, the most efficient way to write this query is to use a single SELECT statement with the MAX function and the GROUP BY clause.\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY MAX(sales_amount) DESC\nLIMIT 1;\n``` \n\nNote that the above queries assume that the sales_amount column is numeric and the product_name column is string. If the data types are different, the queries may need to be adjusted accordingly. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the context of the sales database, the SQL query would be:\n\n```sql\nSELECT product_name\nFROM sales\nGROUP BY product_name\nORDER BY sales_amount DESC\nLIMIT 1;\n``` \n\nThis query will return the product name of the top-selling product. \n\nIn the\nQuery 2 Response: SQL Execution Error: near \"You\": syntax error\n\nGenerated SQL Query:\n You are an AI assistant that translates user questions into SQL queries for a sales database. Convert the following question into a valid SQL query:\n\nWho is the best customer based on spending? \n```\nThe best customer based on spending is the one with the highest total spending amount.\n```\nHere is the `spending` table with the required columns:\n\n| Customer ID | Spending Amount |\n| --- | --- |\n| 1 | 100 |\n| 2 | 200 |\n| 3 | 50 |\n| 4 | 300 |\n| 5 | 400 |\n| 6 | 150 |\n| 7 | 250 |\n| 8 | 350 |\n| 9 | 220 |\n| 10 | 380 |\n\n## Step 1: Identify the required columns and table\nThe required columns are `Customer ID` and `Spending Amount`, and the table is `spending`.\n\n## Step 2: Determine the condition for the best customer\nThe best customer is the one with the highest total spending amount.\n\n## Step 3: Write the SQL query\nTo find the best customer, we need to select the customer with the maximum spending amount. We can use the `MAX` function to achieve this.\n\nThe final answer is: \n```sql\nSELECT Customer ID, Spending Amount\nFROM spending\nORDER BY Spending Amount DESC\nLIMIT 1;\n``` \nHowever, this query returns only one customer, not the entire customer information. To get the entire customer information, we need to join the `spending` table with the `customers` table.\n\nAssuming the `customers` table has the following columns:\n| Customer ID | Customer Name |\n| --- | --- |\n| 1 | John Smith |\n| 2 | Jane Doe |\n| 3 | Bob Brown |\n| 4 | Alice Johnson |\n| 5 | Mike Davis |\n| 6 | Emily Chen |\n| 7 | David Lee |\n| 8 | Sarah Taylor |\n| 9 | Kevin White |\n| 10 | Olivia Brown |\n\n## Step 4: Join the spending and customers tables\nTo get the entire customer information, we need to join the `spending` table with the `customers` table on the `Customer ID` column.\n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nNote: The actual SQL query may vary depending on the specific database management system being used. The above query is written in a generic SQL style and may need to be modified to match the specific requirements of the database. \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM spending s\nJOIN customers c ON s.Customer ID = c.Customer ID\nGROUP BY c.Customer ID, c.Customer Name\nORDER BY Total Spending DESC\nLIMIT 1;\n``` \n\nThe final answer is: \n```sql\nSELECT c.Customer ID, c.Customer Name, SUM(s.Spending Amount) AS Total Spending\nFROM\nQuery 3 Response: SQL Execution Error: near \"You\": syntax error\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install --upgrade langchain langchain_experimental","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:39:01.696350Z","iopub.execute_input":"2025-02-20T20:39:01.696728Z","iopub.status.idle":"2025-02-20T20:39:05.871816Z","shell.execute_reply.started":"2025-02-20T20:39:01.696685Z","shell.execute_reply":"2025-02-20T20:39:05.870930Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.19)\nRequirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.3.4)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.37)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.6)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.18)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.7.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.28.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nimport sqlite3\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nimport re  # To clean and extract SQL from response\n\n# ✅ Step 1: Load LLaMA 3.2 Model\nbase_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    return_dict=True,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\n# Ensure padding token is set correctly\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = model.config.eos_token_id\n\n# Create a text generation pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    max_new_tokens=1024,\n)\n\n# Wrap the pipeline inside LangChain's HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline=pipe)\n\nprint(\"✅ LLaMA 3.2 Model Loaded with LangChain\")\n\n# ✅ Step 2: Connect to SQLite\ndb_path = \"sales_data.db\"\n\ndef connect_db():\n    \"\"\"Creates a SQLite database and inserts sample data if not exists.\"\"\"\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n\n    # Create a sales table\n    cursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS sales (\n        id INTEGER PRIMARY KEY,\n        Customer TEXT,\n        Product TEXT,\n        Quantity INTEGER,\n        Price REAL,\n        Total REAL\n    )\n    \"\"\")\n\n    # Insert sample data if table is empty\n    cursor.execute(\"SELECT COUNT(*) FROM sales\")\n    if cursor.fetchone()[0] == 0:\n        cursor.executemany(\"INSERT INTO sales (Customer, Product, Quantity, Price, Total) VALUES (?, ?, ?, ?, ?)\", [\n            (\"Alice\", \"Laptop\", 1, 1200, 1200),\n            (\"Bob\", \"Phone\", 2, 800, 1600),\n            (\"Charlie\", \"Tablet\", 1, 500, 500),\n            (\"David\", \"Monitor\", 3, 300, 900),\n            (\"Eve\", \"Keyboard\", 2, 100, 200)\n        ])\n        conn.commit()\n    \n    conn.close()\n\n# Create and populate database\nconnect_db()\n\n# ✅ Step 3: Extract Database Schema\ndef get_database_schema():\n    \"\"\"Fetches table schema from SQLite to inform LLaMA.\"\"\"\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n\n    # Get table names\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tables = cursor.fetchall()\n    schema_info = \"\"\n\n    for table in tables:\n        table_name = table[0]\n        schema_info += f\"Table: {table_name}\\n\"\n\n        # Get column details\n        cursor.execute(f\"PRAGMA table_info({table_name});\")\n        columns = cursor.fetchall()\n        for col in columns:\n            schema_info += f\"  - {col[1]} ({col[2]})\\n\"\n        schema_info += \"\\n\"\n\n    conn.close()\n    return schema_info.strip()\n\ndatabase_schema = get_database_schema()\nprint(\"✅ Extracted Database Schema:\\n\", database_schema)\n\n# ✅ Step 4: Define Improved Prompt Template with Schema Awareness\nprompt_template = PromptTemplate(\n    input_variables=[\"query\", \"schema\"],\n    template=\"You are an AI assistant that generates SQL queries for an SQLite database.\\n\\n\"\n             \"Here is the database schema:\\n{schema}\\n\\n\"\n             \"Convert the following question into a valid SQL query. **Only return the SQL query, no explanations.**\\n\\n\"\n             \"Question: {query}\\n\\nSQL Query:\"\n)\n\n# Create LLMChain for generating SQL queries\nllm_chain = LLMChain(llm=llm, prompt=prompt_template)\n\n# ✅ Step 5: Function to process natural language queries on SQLite\ndef ask_sqlite(query):\n    \"\"\"Converts a natural language query to SQL, executes it on SQLite, and returns the result.\"\"\"\n    \n    # Step 5.1: Convert natural language to SQL with schema awareness\n    sql_response = llm_chain.invoke({\"query\": query, \"schema\": database_schema})\n    raw_sql_query = sql_response[\"text\"].strip()\n\n    print(\"\\nGenerated SQL Query (Raw):\\n\", raw_sql_query)  # Debugging\n\n    # Extract clean SQL query using regex\n    sql_match = re.search(r\"SELECT.*?;\", raw_sql_query, re.DOTALL | re.IGNORECASE)\n    if sql_match:\n        sql_query = sql_match.group(0)\n    else:\n        return \"Error: Could not extract SQL query from model response.\"\n\n    print(\"\\nExecuting SQL Query:\\n\", sql_query)  # Debugging\n\n    # Step 5.2: Execute the generated SQL query\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        cursor.execute(sql_query)\n        result = cursor.fetchall()\n        conn.close()\n        \n        return result if result else \"No results found.\"\n    \n    except Exception as e:\n        return f\"SQL Execution Error: {str(e)}\"\n\n# ✅ Step 6: Test with a natural language query\nquery_1 = \"What is the total revenue in the dataset?\"\nquery_2 = \"Which product generated the highest sales?\"\nquery_3 = \"Who is the best customer based on spending?\"\n\nprint(\"Query 1 Response:\", ask_sqlite(query_1))\nprint(\"Query 2 Response:\", ask_sqlite(query_2))\nprint(\"Query 3 Response:\", ask_sqlite(query_3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:45:12.081761Z","iopub.execute_input":"2025-02-20T20:45:12.082130Z","iopub.status.idle":"2025-02-20T20:47:41.898484Z","shell.execute_reply.started":"2025-02-20T20:45:12.082101Z","shell.execute_reply":"2025-02-20T20:47:41.897775Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75827a5d06f4eb3917f6ebb14eba1b2"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"✅ LLaMA 3.2 Model Loaded with LangChain\n✅ Extracted Database Schema:\n Table: sales\n  - id (INTEGER)\n  - Customer (TEXT)\n  - Product (TEXT)\n  - Quantity (INTEGER)\n  - Price (REAL)\n  - Total (REAL)\n\nGenerated SQL Query (Raw):\n You are an AI assistant that generates SQL queries for an SQLite database.\n\nHere is the database schema:\nTable: sales\n  - id (INTEGER)\n  - Customer (TEXT)\n  - Product (TEXT)\n  - Quantity (INTEGER)\n  - Price (REAL)\n  - Total (REAL)\n\nConvert the following question into a valid SQL query. **Only return the SQL query, no explanations.**\n\nQuestion: What is the total revenue in the dataset?\n\nSQL Query: \nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM sales; \n\nSELECT SUM(Total) FROM\n\nExecuting SQL Query:\n SELECT SUM(Total) FROM sales;\nQuery 1 Response: [(4400.0,)]\n\nGenerated SQL Query (Raw):\n You are an AI assistant that generates SQL queries for an SQLite database.\n\nHere is the database schema:\nTable: sales\n  - id (INTEGER)\n  - Customer (TEXT)\n  - Product (TEXT)\n  - Quantity (INTEGER)\n  - Price (REAL)\n  - Total (REAL)\n\nConvert the following question into a valid SQL query. **Only return the SQL query, no explanations.**\n\nQuestion: Which product generated the highest sales?\n\nSQL Query: \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product, SUM(Total) FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product, SUM(Total) FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product, SUM(Total) FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \nSELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1; \n\nSELECT\n\nExecuting SQL Query:\n SELECT Product FROM sales GROUP BY Product ORDER BY SUM(Total) DESC LIMIT 1;\nQuery 2 Response: [('Phone',)]\n\nGenerated SQL Query (Raw):\n You are an AI assistant that generates SQL queries for an SQLite database.\n\nHere is the database schema:\nTable: sales\n  - id (INTEGER)\n  - Customer (TEXT)\n  - Product (TEXT)\n  - Quantity (INTEGER)\n  - Price (REAL)\n  - Total (REAL)\n\nConvert the following question into a valid SQL query. **Only return the SQL query, no explanations.**\n\nQuestion: Who is the best customer based on spending?\n\nSQL Query: \n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY TotalSpent DESC\nLIMIT 1\n``` \n\nHowever, this query returns only the top customer, not the top customer based on total spending. The question asks for the customer who has spent the most, so the customer with the highest total spent should be returned, not just the top customer.\n\nTo answer this question, we can use the following query:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY TotalSpent DESC\n```\n\nHowever, this query will still return only one customer, because it uses the `DESC` keyword, which returns the top value. To return the customer who has spent the most, we need to use the `ORDER BY` keyword with the `ASC` keyword, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY TotalSpent ASC\n```\n\nHowever, the `ORDER BY` keyword is used to sort the results, so we can't use it to return only the top customer. To return the top customer, we need to use the `LIMIT` keyword with the `OFFSET` keyword, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY TotalSpent DESC\nLIMIT 1 OFFSET 0\n```\n\nHowever, the `OFFSET` keyword is used to skip a number of rows, so we can't use it to return only the top customer. To return the top customer, we need to use a subquery, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nHAVING SUM(Quantity * Price) = (SELECT MAX(TotalSpent) FROM (SELECT Customer, SUM(Quantity * Price) AS TotalSpent FROM sales GROUP BY Customer))\n```\n\nHowever, the subquery is not necessary, we can simply use the `MAX` function directly on the `SUM(Quantity * Price)` expression, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nHAVING SUM(Quantity * Price) = (SELECT MAX(SUM(Quantity * Price)) FROM sales GROUP BY Customer)\n```\n\nHowever, the above query still returns only one customer, because the `HAVING` clause is used to filter groups, so we need to use the `ORDER BY` keyword with the `ASC` keyword to return the customer who has spent the most, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, this query will return the customer who has spent the most, but it will not return the customer's name. To return the customer's name, we need to use the `ROW_NUMBER()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, the `ROW_NUMBER()` function is not supported in SQLite, so we need to use a different approach. We can use the `DENSE_RANK()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, the `DENSE_RANK()` function is not supported in SQLite, so we need to use a different approach. We can use the `RANK()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, the `RANK()` function is not supported in SQLite, so we need to use a different approach. We can use the `LAG()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, the `LAG()` function is not supported in SQLite, so we need to use a different approach. We can use the `PERCENT_RANK()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nGROUP BY Customer\nORDER BY SUM(Quantity * Price) DESC\n```\n\nHowever, the `PERCENT_RANK()` function is not supported in SQLite, so we need to use a different approach. We can use the `NTILE()` function, like so:\n\n```sql\nSELECT Customer, SUM(Quantity * Price) AS TotalSpent\nFROM sales\nQuery 3 Response: Error: Could not extract SQL query from model response.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}